\section{Preparation}\label{sec:prep}
Before the data can be further processed and used, some simple preparation
must be done to normalise the data.
This section discusses the transformative steps and the end representation that
the program will work with from the initial state until classification.

\subsection{Resampling}
All recordings are normalised to the same format properties, since the source
material varies greately from sample to sample.

Variations include:
\begin{itemize}[noitemsep]
  \item Audio channels;
  \item Bit depth;
  \item Sample rate;
  \item Length.
\end{itemize}

If a recording is found to have more than a single channel, all but the left
channel are discarded.

Sample rate reductions are made to reduce the memory and processing demands of
analysing all 231231 minutes of audio.
Our image recognition approach holds greater importance to the general shape
of individual vocalisations in spectrograms, rather than high time-frequency
details.
Because of this, the sample rate reduction is found to have no significant
reductions in classification quality.

The recording length is left unaltered.

The ffmpeg program is used to convert all source material to 22050 Hz 16-bit
WAV files.
We have written a shell script to make this procedure fully automatic, executable
when new recordings have been sourced.



\subsection{Spectrogram Representation}
A spectrogram image provides a wealth of additional information that can be used
to visualise the audio data as energy per frequency band as a function of time.
Figure x shows that the spectrogram representation retains amplitude information
while exposing the frequencies which make up the signal.

\textbf{show spectrogram image under waveform of same section}

Our image recognition approach makes use of this spectrographic representation
of the field recordings.

Spectrogram construction is processed as a discrete stage in our program, which
processes all audio files and stores their spectrograms to disk.
Spectrogram construction is unintensive work on modern CPUs, making this stage
relatively quick.
Processing each audio file takes x minutes in total.
The source WAV files are loaded and read as pulse-code modulation (PCM) data.
Spectrogram images are then constructed using a fast fourier transform (FFT) method,
which is a efficient disscrete fourier transform (DFT).
The details of the FFT mechanism can be found in \textbf{appendix x}.
The Python Matplotlib library's specgram function is used to generate spectrograms.

The following parameters are used:
\begin{itemize}[noitemsep]
  \item \textbf{NFFT: 512}.
    NFFT defines the number of data points used in each block.
  \item \textbf{Window: Hann window of 512.}
    Windowing functions minimise spectral leakage in the signal by tapering the ends
    of the window.
    simplify and move to appendix
  \item \textbf{Overlap: 75\%}.
    Overlap defines the number of points overlapping between blocks.
\end{itemize}

See Appendix for details on FFTS.

Frequencies above 10000Hz and below 100Hz are removed from the spectrograms as these do
not contain signals belonging to any bird species \textbf{(cite)}.
