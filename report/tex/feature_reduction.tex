\section{Feature Importance}\label{sec:feature_imp}
Because our feature vector is directly related to the templates of each species,
it is possible to determine their role and effectiveness in classifying a
recording by computing feature importances from our classifier.
This allows us to reduce the number of templates involved in classifying a given
sample, significantly cutting down the cost of template matching per species.
Feature importances also help us analyse the preprocessing performance in detail,
as well as correlate inter-species similarities in cases where there is a high
level of confusion.

\subsection{In Random Forests}

\subsubsection{Mean decrease accuracy}
One method for measuring the impact of each feature is through the mean decrease
in accuracy.
With this method, the impact of removing each feature one-by-one is measured.
This method may be sensitive to the random nature of the classifier, so multiple
runs may be required to eliminate any variance (is this true?).
This can be prohibitively expensive.

\subsubsection{Mean decrease impurity}
Because the nodes of trees in a random forest correlate directly with a specific
feature, it is possible to directly measure or estimate the importance of each
feature by determining the probability of a node in a tree being traversed over 
the number of nodes in the forest.
This is known as the mean decrease impurity, or gini importance, which is what
is used in Sckikit's random forest classifier implementation.

\subsection{Results and Analysis}

Measuring feature importances exposes an average of x out of 3000 samples as
completely irrelevant during training and classification.
Removing these features shows no reduction in accuracy, and a significant speedup
during template matching is gained, reducing total classification time from 10000
hours to 0.5 seconds.

There are 1209301293123 templates distributed across 20 spectrograms for each
of the 50 species selected.
When clsasifying a new sample, it's spectrogram must be cross-correlated with
each of the templates.
This operation is extremely expensive, in the order of 42 hours, or 25 seconds
per template of average dimensions (125x125) with a target sample of average
length (3 minutes). (see apndx 1 for detailed time analysis)

The aim is therefore to reduce the feature count as much as possible while
retaining the highest possible accuracy by determining an appropriate importance
cutoff.
Removing features and reevaluating the classifier takes no significant time in
contrast to template extraction and may therefore be done by iteratively removing
and checking classifier accuracy, adjusting the importance cutoff accordingly.
Measuring feature importance unfortunately requires a complete run which involves
the cross-correlation of all templates, which negates any performance benefits
for recordings which aren't new to the system.
Since we are using cross-validation to evaluate all samples, all templates are
used eventually, even if their importances remain low across all folds.\\

Feature reduction is very helpful during feature extraction, when merging the
results of two batches.
Templates with importance scores equalling or close to zero can be safely removed
from the set before merging, saving a considerable amount of time.
Time saved is estimated to be 232103 minutes on average.

\textbf{unless we can get importances from training only, then when we test
we can use the reduced template set and speed all this up}

\textbf{graph of feature importances}\\


\textbf{paragraph on important and non important feature analysis. lots of 
images, look at templates belonging to confused species, try to determine
which are culprits, probably most of them}
