\section{Feature Engineering}\label{sec:ccm}
With a collection of extracted templates from each spectrogram, feature vectors
can be constructed to distinguish between various bird species.
This is done through cross-correlation mapping, an image recognition algorithm.
A feature vector is derived from the results of cross-correlating all
templates against samples of known species.
These feature vectors are then used to train a machine learning algorithm to
classify new recordings from their spectrograms.

This section describes the mechanisms used to perform cross-correlation mapping
for feature vector construction and a short analysis of the computational
expense involved.

\subsection{Batch Processing}
Once initial reductions have been made through the selection process,
further processing is batched in groups of four species, which are selected in
random order without replacement.
Each batch undergoes template matching, the results of which are stored on disk.
Once a batch is completed it is merged with previous results by cross-template
matching the new templates against the old spectrograms and the old templates
against the new spectrograms.
The new results are appended to the old feature vectors and stored on disk.

This is an effective method for dividing work into managable chunks while storing
intermediate results.
The cost analysis in the following section justifies the need for batching.

\subsection{Template Matching}
Template matching is a method for computing the similarity of an image within
another.
We use a normalised cross-correlation method for template matching.
This mode was chosen over squared-difference and cosine-coefficient because it
has been used with good results in similar spectrogram template matching tasks
(\textcite{lasseck2013}).
Normalisation is used to reduce the effect of background noise in the
spectrogram images.

The result of cross-correlation is a 2-dimensional vector of equal dimensions to
the target image, where values are normalised from 0 to 1 (Figure~\ref{fig:ccm}).
Greater values indicate a higher level of correlation for the template in that
area.
This can be thought of and visualised as a heatmap of the template's correlation.

\begin{figure}[t!]
  \centering
  \begin{subfigure}[t]{0.5\textwidth}
    \centering
    \caption{}
  \end{subfigure}
  \begin{subfigure}[t]{0.5\textwidth}
    \centering
    \caption{}
  \end{subfigure}
  \begin{subfigure}[t]{0.5\textwidth}
    \centering
    \caption{}
  \end{subfigure}
  \caption{Visualisation of a cross-correlation mapping (c) of template (a) against
  spectrogram (b)}
  \label{fig:ccm}
\end{figure}

Section~\ref{sec:feature_imp} discusses the mechanism for and analysis of feature
importance.

\subsubsection{Implementation and cost}
We use Open-CV's |matchTemplate| function with the normalised CCM method.
It's implementation uses a Fourer analysis approach for improved performance over
the traditional raw statistical methods.
This works by first applying a FFT to the template and target image before
performing the cross-correlation.
\textbf{cant find ref, look at code?}

Even with such optimizations, template matching takes a considerable amount of
time.
Template matching takes on average x minutes per template, given
mean size of m and n pixels for spectrograms and templates respectively.
Considering the quantity of templates being analysed, the time required quickly
amounts to days.

To gain insight into how the requirements respond to the size of a
spectrogram, a feature extraction run was performed for 80 spectrograms of
varying sizes, with 12204 templates.
Spectrograms and templates were selected at random following the same selection
and filtering procedures described in previous sections.
Total time to completion was approximately 22 hours on the machine listed in
Appendix~\ref{app:machine}.\\

\begin{figure}[!htb]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\textwidth]{ccm_time_sgram}
    \caption{}
  \end{subfigure}%
  \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=1.0\textwidth]{ccm_mem_sgram}
    \caption{}
  \end{subfigure}
  \caption{Time (a) and resident memory (b) usages as pixel count increases for
  cross-correlation against 12204 templates}
\end{figure}

Further optimisations have been implemented.
In particular, dimensionality reduction is performed on templates and
spectrograms by blurring and reducing their size as seen in
Section~\ref{sec:extract}.

In addition, template matching is multithreaded using Python's |multiprocessing|
module.
Spectrograms are split into even chunks equalling the number of usable CPUs on
the machine, joining results upon completion.
This cuts the cost down to approximately $1/4$ of the original time.\\

Additional optimizations could, but have not been implemented:
\begin{itemize}[noitemsep]
  \item Template matching can be confined to the general area at which the template
    was extracted.
    This is possible if the frequency bands, or image coordinates at which a
    template was extracted is stored for this purpose.
    If implemented, the search area for template matching should be increased by some
    value to account for natural or artificial deviations.

  \item Open-CV's template matching function supports on-GPU calculations.
    Doing so would result in considerable gains in speed, however this requires
    an NVIDIA CUDA device (http://docs.opencv.org/2.4/modules/gpu/doc/introduction.html).

  \item Open-CV uses FFT.
    Fast Normalised Cross Correlation (FNCC) is a faster alternative to FFT based
    methods of template matching (TemplateMatchingusingFastNormalizedCrossCorrelationKaiBriechleandUweDHanebeck).
    Replacing calls to an implementation which uses FNCC would result in some 
    performance gains, however an existing implementation has not been found,
    and writing one from scratch is expensive without a guarantee of noticeable
    impact.
\end{itemize}

\subsection{Feature Vector Construction}
The template matching results are used to construct a feature vector for each
recording.
The feature vector of each sample therefore encodes the extent at which it's
recording contains similar characteristics to each species' song.
Feature vectors compose the training and test data for machine learning in
Chapter~\ref{cha:clf}.

The length of each feature vector is constant across all species and is equal to
the number of extracted templates.
The values of each element in the vector are derived from the template matching
results by taking the maximum value from the cross-correlation mapping.
The maxima intuitively gives us the highest matching probability for a template,
but discards information of other possible matches.
This extraction has shown promising results (\textcite{fodor2013}).
